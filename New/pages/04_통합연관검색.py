import streamlit as st
from modules.suam_analysis import load_analysis
from modules.terminology import load_terms
# í•„ìš”ì‹œ: from modules.basic_theory import load_theory
# í•„ìš”ì‹œ: from modules.case_studies import load_cases
import pandas as pd

# ------ 1. ë°ì´í„° ë¡œë”© ------
suam_data = load_analysis()         # êµ¬ì¡° í•´ì„ ë°ì´í„° (ë¦¬ìŠ¤íŠ¸)
terms_data = load_terms()           # ëª…ë¦¬ ìš©ì–´ ë°ì´í„° (ë¦¬ìŠ¤íŠ¸)
# theory_data = load_theory()      # ì´ë¡  ë°ì´í„° (ì˜µì…˜)
# cases_data = load_cases()        # ì‚¬ë¡€ ë°ì´í„° (ì˜µì…˜)

# ------ 2. UI : ì—°ê´€ê²€ìƒ‰ ì…ë ¥ ------
st.title("ğŸ” ìˆ˜ì•”ëª…ë¦¬ êµ¬ì¡°í•´ì„ & ìš©ì–´/ì´ë¡ /ì‚¬ë¡€ ì—°ê´€ê²€ìƒ‰")
st.markdown("""
ëª…ì‹Â·ì£¼ì œÂ·ë¶„ì„Â·í‚¤ì›Œë“œë¡œ êµ¬ì¡° í•´ì„ DBë¥¼ ê²€ìƒ‰í•˜ê³ ,  
ìë™ìœ¼ë¡œ **ì—°ê´€ ëª…ë¦¬ìš©ì–´/ì´ë¡ /ì‚¬ë¡€**ê¹Œì§€ í†µí•© í‘œì¶œí•©ë‹ˆë‹¤.
""")

search_kw = st.text_input("ê²€ìƒ‰ì–´(ëª…ì‹Â·ì£¼ì œÂ·ë¶„ì„Â·ìš©ì–´Â·ì£¼ìš” ë‹¨ì–´ ë“±)", "")
search_btn = st.button("ì—°ê´€ìë£Œ í†µí•©ê²€ìƒ‰")

# ------ 3. êµ¬ì¡° í•´ì„ DB ê²€ìƒ‰ ------
if search_btn and search_kw:
    # 1ì°¨: êµ¬ì¡° í•´ì„ DB ê²€ìƒ‰
    def item_match(item, kw):
        return any(kw in str(item.get(f, "")) for f in
                   ["ëª…ì‹_ì²œê°„", "ëª…ì‹_ì§€ì§€", "ì£¼ì œ", "êµ¬ì¡°_í‘œ", "ì²œê°„_ë¶„ì„", "ì§€ì§€_ë¶„ì„", "í•©ì¶©_ë¶„ì„", "í˜„ì‹¤_ì‘ìš©"])

    suam_hits = [item for item in suam_data if item_match(item, search_kw)]
    st.markdown(f"### ğŸŒ€ êµ¬ì¡° í•´ì„ ê²°ê³¼ ({len(suam_hits)}ê±´)")
    if suam_hits:
        for i, item in enumerate(suam_hits):
            st.markdown(f"---\n#### {i+1}. [ëª…ì‹] {item['ëª…ì‹_ì²œê°„']} / {item['ëª…ì‹_ì§€ì§€']}")
            st.markdown(f"- **ì£¼ì œ:** {item['ì£¼ì œ']}")
            st.markdown(f"- **[1. êµ¬ì¡° í‘œ]**\n{item['êµ¬ì¡°_í‘œ']}")
            st.markdown(f"- **[2. ì²œê°„]**\n{item['ì²œê°„_ë¶„ì„']}")
            st.markdown(f"- **[3. ì§€ì§€]**\n{item['ì§€ì§€_ë¶„ì„']}")
            st.markdown(f"- **[4. í•©ì¶©]**\n{item['í•©ì¶©_ë¶„ì„']}")
            st.markdown(f"- **[5. í˜„ì‹¤ì‘ìš©]**\n{item['í˜„ì‹¤_ì‘ìš©']}")
    else:
        st.info("êµ¬ì¡° í•´ì„ ë°ì´í„°ì—ì„œ ê²°ê³¼ ì—†ìŒ.")

    # 2ì°¨: ì—°ê´€í‚¤ì›Œë“œ ì¶”ì¶œ (ëª…ì‹ ê¸€ì/ì£¼ì œ/ë¶„ì„ ë‹¨ì–´)
    rel_keywords = set()
    for item in suam_hits:
        rel_keywords.update(item["ëª…ì‹_ì²œê°„"].split())
        rel_keywords.update(item["ëª…ì‹_ì§€ì§€"].split())
        rel_keywords.update(item["ì£¼ì œ"].split())
        rel_keywords.update(item["ì²œê°„_ë¶„ì„"].split())
        rel_keywords.update(item["ì§€ì§€_ë¶„ì„"].split())
        rel_keywords.update(item["í•©ì¶©_ë¶„ì„"].split())
        rel_keywords.update(item["í˜„ì‹¤_ì‘ìš©"].split())

    # 3ì°¨: ëª…ë¦¬ ìš©ì–´ ì—°ê´€ ê²€ìƒ‰
    def term_match(term):
        return any(k in term["Term"] or k in term.get("Meaning", "") for k in rel_keywords)
    term_hits = [t for t in terms_data if term_match(t)]

    st.markdown("### ğŸ“š ì—°ê´€ ëª…ë¦¬ ìš©ì–´")
    if term_hits:
        st.dataframe(pd.DataFrame(term_hits))
    else:
        st.info("ì—°ê´€ ìš©ì–´ ê²°ê³¼ ì—†ìŒ.")

    # 4ì°¨: (ì„ íƒ) ì—°ê´€ ì´ë¡ /ì‚¬ë¡€
    # if 'theory_data' in locals():
    #     theory_hits = [t for t in theory_data if any(k in t["Concept"] or k in t["Category"] or k in t["Detail"] for k in rel_keywords)]
    #     st.markdown("### ğŸ“– ì—°ê´€ ì´ë¡ ")
    #     if theory_hits:
    #         st.dataframe(pd.DataFrame(theory_hits))
    #     else:
    #         st.info("ì—°ê´€ ì´ë¡  ì—†ìŒ.")

    # if 'cases_data' in locals():
    #     case_hits = [c for c in cases_data if any(k in c["Analysis"] or k in c["Result"] for k in rel_keywords)]
    #     st.markdown("### ğŸ”¬ ì—°ê´€ ì‹¤ì „ ì‚¬ë¡€")
    #     if case_hits:
    #         st.dataframe(pd.DataFrame(case_hits))
    #     else:
    #         st.info("ì—°ê´€ ì‚¬ë¡€ ì—†ìŒ.")

    # 5ì°¨: (ì„ íƒ) ì „ì²´ í†µí•© í…Œì´ë¸”ë¡œ í•œ ë²ˆì— ì¶œë ¥ (í•„ìš”ì‹œ)
else:
    st.info("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥ í›„ [ì—°ê´€ìë£Œ í†µí•©ê²€ìƒ‰] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

st.caption("êµ¬ì¡° í•´ì„/ëª…ë¦¬ ìš©ì–´/ì´ë¡ /ì‚¬ë¡€ ì—°ê´€ ê²°ê³¼ë¥¼ í†µí•© ì œê³µ")
